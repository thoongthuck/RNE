{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thoongthuck/RNE/blob/main/VAD_%ED%9A%8C%EA%B7%80.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 오디오 VAD"
      ],
      "metadata": {
        "id": "Om9vcnYVe4Hs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cmath\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from lightgbm import LGBMRegressor\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "Kq1nVTSEfz-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ZouWfIL4f2s9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data load\n",
        "audio_data = pd.read_csv('/content/drive/MyDrive/RNE/LGBM/LGBM_train.csv')\n",
        "\n",
        "audio_labeled = pd.read_csv('/content/drive/MyDrive/RNE/LGBM/train/static_annotations_averaged_songs_1_2000.csv')\n",
        "\n",
        "audio_labeled.rename(columns={'song_id':'id'},inplace=True)\n",
        "audio_data.drop_duplicates(inplace=True)\n",
        "\n",
        "VA = [' valence_mean',' arousal_mean']\n",
        "\n",
        "audio_df = pd.merge(audio_labeled[['id']+VA],audio_data,on='id',how='inner')\n",
        "audio_df.dropna(inplace=True)\n",
        "audio_df[VA] = (audio_df[VA]-1)/8"
      ],
      "metadata": {
        "id": "3F8jVjzSf4du"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.kdeplot(audio_df[VA])"
      ],
      "metadata": {
        "id": "lHrYhxdUf5Xk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "V_regressor"
      ],
      "metadata": {
        "id": "_MEBsHVogDtP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data preprocessing\n",
        "X = audio_df.iloc[:,3:]\n",
        "y = audio_df[' valence_mean']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "X_test.shape"
      ],
      "metadata": {
        "id": "pztG5McQgF60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "params = {\n",
        "    'n_estimators': [600],\n",
        "    'max_depth': [5],\n",
        "    'learning_rate': [0.01],\n",
        "    'min_data_in_leaf': [10],\n",
        "    'feature_fraction': [0.6],\n",
        "    'bagging_fraction': [0.8],\n",
        "    'num_leaves': [50]\n",
        "}\n",
        "\n",
        "V_model = LGBMRegressor(\n",
        "    bagging_freq=5,\n",
        "    reg_alpha=0.1,\n",
        "    reg_lambda=0.1,\n",
        "    random_state=42,\n",
        "    verbose=-1\n",
        "  )\n",
        "\n",
        "grid_cv = GridSearchCV(V_model,param_grid=params, cv=5, scoring='r2', refit=True)\n",
        "grid_cv.fit(X_train, y_train)\n",
        "\n",
        "best_V_model = grid_cv.best_estimator_\n",
        "pred = best_V_model.predict(X_test)\n",
        "\n",
        "r2 = r2_score(y_test, pred)\n",
        "mse = np.sqrt(mean_squared_error(y_test, pred))\n",
        "mae = mean_absolute_error(y_test, pred)\n",
        "\n",
        "print('파라미터:\\n', grid_cv.best_params_)\n",
        "print(f'test R2: {r2:.4f}')\n",
        "print(f'MSE: {mse:.4f}')\n",
        "print(f'MAE: {mae:.4f}')"
      ],
      "metadata": {
        "id": "83PaVHnigG2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importance\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "ftr_importances_values = best_V_model.feature_importances_\n",
        "ftr_importances = pd.Series(ftr_importances_values,index=X_train.columns)\n",
        "ftr_top = ftr_importances.sort_values(ascending=False)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.title('Feature importances')\n",
        "sns.barplot(x=ftr_top , y = ftr_top.index)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-UPJnlc6gIMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A_regressor"
      ],
      "metadata": {
        "id": "nbyL56rogL_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = audio_df.iloc[:,3:]\n",
        "y = audio_df[' arousal_mean']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "ga-nWHP-gLYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    'n_estimators': [1000],\n",
        "    'max_depth': [13],\n",
        "    'learning_rate': [0.01],\n",
        "    'min_data_in_leaf': [23],\n",
        "    'feature_fraction': [0.6],\n",
        "    'bagging_fraction': [0.6],\n",
        "    'num_leaves': [12]\n",
        "}\n",
        "\n",
        "A_model = LGBMRegressor(\n",
        "    boosting_type='dart',\n",
        "    eval_metric='rmse',\n",
        "    random_state=42,\n",
        "    verbose=-1\n",
        "  )\n",
        "\n",
        "grid_cv = GridSearchCV(A_model,param_grid=params, cv=5, scoring='r2', refit=True)\n",
        "grid_cv.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X_test,y_test)]\n",
        "  )\n",
        "\n",
        "best_A_model = grid_cv.best_estimator_\n",
        "pred = best_A_model.predict(X_test)\n",
        "\n",
        "r2 = r2_score(y_test, pred)\n",
        "mse = np.sqrt(mean_squared_error(y_test, pred))\n",
        "mae = mean_absolute_error(y_test, pred)\n",
        "\n",
        "print('파라미터:\\n', grid_cv.best_params_)\n",
        "print(f'test R2: {r2:.4f}')\n",
        "print(f'MSE: {mse:.4f}')\n",
        "print(f'MAE: {mae:.4f}')"
      ],
      "metadata": {
        "id": "JzR6YN-WgP8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ftr_importances_values = best_A_model.feature_importances_\n",
        "ftr_importances = pd.Series(ftr_importances_values,index=X_train.columns)\n",
        "ftr_top = ftr_importances.sort_values(ascending=False)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.title('Feature importances')\n",
        "sns.barplot(x=ftr_top , y = ftr_top.index)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QGVHAhYwgRtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mapping"
      ],
      "metadata": {
        "id": "9Z_F2Yu0gWAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/RNE/song_features.csv')\n",
        "\n",
        "df = df.iloc[:,:46]\n",
        "df.drop_duplicates(inplace=True)\n",
        "df.info()"
      ],
      "metadata": {
        "id": "QFC4ah6CgVli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feats = df.iloc[:,2:]\n",
        "meta = df.iloc[:,:2]\n",
        "feats.shape\n",
        "for _ in range(len(feats)):\n",
        "  V_pred = best_V_model.predict(feats)\n",
        "  A_pred = best_A_model.predict(feats)\n",
        "  meta['V_audio'] = V_pred\n",
        "  meta['A_audio'] = A_pred\n",
        "\n",
        "meta.to_csv('/content/drive/MyDrive/RNE/test/VA_audio.csv')\n",
        "meta.head()"
      ],
      "metadata": {
        "id": "x8MHWKUhgYls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 가사 VAD"
      ],
      "metadata": {
        "id": "n5BpjgRvez_o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qgxj3XnREqDo"
      },
      "outputs": [],
      "source": [
        "!pip install transformers sentencepiece -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6c5mSPCNx4m"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMkMtLpBEr9N"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import torch.nn.functional as F\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vpt_OgMyu47x"
      },
      "outputs": [],
      "source": [
        "# preprocessing\n",
        "df = pd.read_csv('/content/drive/MyDrive/RNE/Bert/train/lyric_df_translated.csv')\n",
        "df = df.drop('text',axis=1)\n",
        "df.rename(columns={'trans':'text'},inplace=True)\n",
        "df.dropna(subset=['text'],inplace=True)\n",
        "df[['V','A','D']] = (df[['V','A','D']]-1)/4\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.kdeplot(x=df['V'],label='Valence')\n",
        "sns.kdeplot(x=df['A'],label='Arousal')\n",
        "sns.kdeplot(x=df['D'],label='Dominence')\n",
        "plt.xlabel('value')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M_mZdm_w7cXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPKvohbzEvpC"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = 'klue/bert-base'\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3B5XuRTEyMs"
      },
      "outputs": [],
      "source": [
        "# dataset\n",
        "class VADDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, max_length=128):\n",
        "        self.texts = df['text'].tolist()\n",
        "        self.labels = df[['V', 'A', 'D']].values\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "    def __len__(self): return len(self.texts)\n",
        "    def __getitem__(self, idx):\n",
        "        encoding = self.tokenizer(\n",
        "            str(self.texts[idx]),\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "        labels = torch.tensor(self.labels[idx], dtype=torch.float)\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
        "            'labels': labels\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_everything(42)"
      ],
      "metadata": {
        "id": "C4AQl1eNBqV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCAu3Gk3E2MB"
      },
      "outputs": [],
      "source": [
        "# model\n",
        "class KLUEBERT_VAD(nn.Module):\n",
        "    def __init__(self, model_name):\n",
        "        super().__init__()\n",
        "        self.bert = AutoModel.from_pretrained(model_name)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.fc1 = nn.Linear(768, 256, bias=True)\n",
        "        self.fc2 = nn.Linear(256, 64, bias=True)\n",
        "        self.fc3 = nn.Linear(64, 3, bias=True)\n",
        "\n",
        "    def MLP(self, x):\n",
        "      x = F.relu(self.fc1(x))\n",
        "      x = self.dropout(F.relu(self.fc2(x)))\n",
        "      x = self.fc3(x)\n",
        "      return x\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        hidden = outputs.last_hidden_state[:, 0, :]\n",
        "        return self.MLP(self.dropout(hidden))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lACUm5x5E5v-"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnaaQcqHE_dw"
      },
      "outputs": [],
      "source": [
        "# dataLoader\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "train_ds = VADDataset(train_df, tokenizer)\n",
        "val_ds = VADDataset(val_df, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=8, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=8, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PR33AQwrF-8N"
      },
      "outputs": [],
      "source": [
        "#model\n",
        "model = KLUEBERT_VAD(MODEL_NAME).to(device)\n",
        "for name, param in model.bert.named_parameters():\n",
        "  if \"layer.10\" in name or \"layer.11\" in name:\n",
        "      param.requires_grad = True\n",
        "  else:\n",
        "      param.requires_grad = False\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(),lr=1e-4)\n",
        "criterion = nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W77ZUX2zFyKe"
      },
      "outputs": [],
      "source": [
        "# train\n",
        "EPOCHS = 7\n",
        "patience = 3\n",
        "best_loss = float('inf')\n",
        "patience_counter = 0\n",
        "total_steps = len(train_loader) * EPOCHS\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, 0, num_training_steps=total_steps)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(input_ids, attention_mask)\n",
        "        loss = criterion(preds, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_loader)\n",
        "\n",
        "    # validation Loss\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    val_preds, val_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            preds = model(input_ids, attention_mask)\n",
        "            loss = criterion(preds, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            val_preds.append(preds.cpu().numpy())\n",
        "            val_labels.append(labels.cpu().numpy())\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch+1} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "    # early Stopping\n",
        "    if avg_val_loss < best_loss:\n",
        "        best_loss = avg_val_loss\n",
        "        patience_counter = 0\n",
        "        torch.save(model.state_dict(), \"/content/drive/MyDrive/rne/Bert/kluebert_vad.pt\")\n",
        "        print(f\"모델 저장 ({best_loss:.4f})\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        print(f\"개선 없음 ({patience_counter}/{patience})\")\n",
        "\n",
        "    if patience_counter >= patience:\n",
        "        print(\"학습 중단\")\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4J1m1v_QgBG1"
      },
      "outputs": [],
      "source": [
        "# evaluation\n",
        "model.eval()\n",
        "val_preds, val_labels = [], []\n",
        "with torch.no_grad():\n",
        "  for batch in val_loader:\n",
        "    input_ids = batch['input_ids'].to(device)\n",
        "    attention_mask = batch['attention_mask'].to(device)\n",
        "    labels = batch['labels'].to(device)\n",
        "    preds = model(input_ids, attention_mask)\n",
        "    val_preds.append(preds.cpu().numpy())\n",
        "    val_labels.append(labels.cpu().numpy())\n",
        "\n",
        "val_preds = np.concatenate(val_preds, axis=0)\n",
        "val_labels = np.concatenate(val_labels, axis=0)\n",
        "\n",
        "mse = mean_squared_error(val_labels, val_preds)\n",
        "mae = mean_absolute_error(val_labels, val_preds)\n",
        "r2 = r2_score(val_labels, val_preds)\n",
        "print(f'mse: {mse:.4f} | mae: {mae:.4f} | R2: {r2:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95fQqq4OFCz5"
      },
      "outputs": [],
      "source": [
        "# prediction\n",
        "def predict_vad(text):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=128).to(device)\n",
        "        preds = model(inputs['input_ids'], inputs['attention_mask'])\n",
        "        preds = preds.detach().cpu().numpy().flatten()\n",
        "    return {'valence': float(preds[0]), 'arousal': float(preds[1]), 'dominance': float(preds[2])}\n",
        "\n",
        "print(predict_vad(\"지배\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNbsukB5FEyz"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), '/content/drive/MyDrive/rne/Bert/klue_vad.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SE0X2UD-R818"
      },
      "source": [
        "# Loaded Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qISY93xFJ7l"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# model\n",
        "MODEL_NAME = 'klue/bert-base'\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "loaded_model = KLUEBERT_VAD(MODEL_NAME).to(device)\n",
        "\n",
        "# load model\n",
        "loaded_model.load_state_dict(torch.load('/content/drive/MyDrive/RNE/Bert/kluebert_vad.pt'))\n",
        "print(\"모델이 성공적으로 불러와졌습니다.\")\n",
        "\n",
        "loaded_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AlIbJNZ-6HN5"
      },
      "outputs": [],
      "source": [
        "# evaluation\n",
        "loaded_model.eval()\n",
        "val_preds, val_labels = [], []\n",
        "with torch.no_grad():\n",
        "  for batch in val_loader:\n",
        "    input_ids = batch['input_ids'].to(device)\n",
        "    attention_mask = batch['attention_mask'].to(device)\n",
        "    labels = batch['labels'].to(device)\n",
        "    preds = loaded_model(input_ids, attention_mask)\n",
        "    val_preds.append(preds.cpu().numpy())\n",
        "    val_labels.append(labels.cpu().numpy())\n",
        "\n",
        "val_preds = np.concatenate(val_preds, axis=0)\n",
        "val_labels = np.concatenate(val_labels, axis=0)\n",
        "\n",
        "mse = mean_squared_error(val_labels, val_preds)\n",
        "mae = mean_absolute_error(val_labels, val_preds)\n",
        "r2 = r2_score(val_labels, val_preds)\n",
        "print(f'mse: {mse:.4f} | mae: {mae:.4f} | R2: {r2:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqDUxKaZHwEC"
      },
      "outputs": [],
      "source": [
        "# prediction\n",
        "def predict_vad(text):\n",
        "    loaded_model.eval()\n",
        "    with torch.no_grad():\n",
        "        inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=128).to(device)\n",
        "        preds = loaded_model(inputs['input_ids'], inputs['attention_mask'])\n",
        "        preds = preds.detach().cpu().numpy().flatten()\n",
        "    return {'valence': float(preds[0]), 'arousal': float(preds[1]), 'dominance': float(preds[2])}\n",
        "\n",
        "print(predict_vad(\"안녕하세요!\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNy9gLL7skBx"
      },
      "outputs": [],
      "source": [
        "# data load\n",
        "lyric_df = pd.read_csv('/content/drive/MyDrive/rne/lyric_df.csv',encoding='utf-8')\n",
        "song_df = pd.read_csv('/content/drive/MyDrive/rne/VA_audio.csv',encoding='utf-8')\n",
        "\n",
        "song_feat = pd.merge(song_df,lyric_df,on=['title','artist'])\n",
        "\n",
        "song_feat.drop_duplicates(inplace=True,subset=['title', 'artist'])\n",
        "song_feat.drop(['Unnamed: 0_x','Unnamed: 0_y'], axis=1, inplace=True)\n",
        "\n",
        "song_feat.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkxT7TnGqoh3"
      },
      "outputs": [],
      "source": [
        "# Regress V-A-D\n",
        "records = []\n",
        "\n",
        "for idx, lyric in enumerate(song_feat['lyric']):\n",
        "    predict = predict_vad(lyric)\n",
        "    record = {\n",
        "        \"title\": song_feat['title'].iloc[idx],\n",
        "        \"artist\": song_feat['artist'].iloc[idx],\n",
        "        \"V_lyric\": predict['valence'],\n",
        "        \"A_lyric\": predict['arousal'],\n",
        "        \"D_lyric\": predict['dominance']\n",
        "    }\n",
        "    records.append(record)\n",
        "\n",
        "VAD_lyric = pd.DataFrame(records)\n",
        "VAD_lyric = pd.merge(song_feat, VAD_lyric, on=['title','artist']).drop('lyric',axis=1)\n",
        "VAD_lyric['V'] = 0.6*VAD_lyric['V_audio'] + 0.4*VAD_lyric['V_lyric']\n",
        "VAD_lyric['A'] = 0.2*VAD_lyric['A_audio'] + 0.8*VAD_lyric['A_lyric']\n",
        "VAD_lyric['D'] = VAD_lyric['D_lyric']\n",
        "VAD_lyric.describe()\n",
        "\n",
        "VAD_lyric.to_csv('/content/drive/MyDrive/VAD_song.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}